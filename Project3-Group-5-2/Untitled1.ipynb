{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nHbh14cml-IY","executionInfo":{"status":"ok","timestamp":1629250808652,"user_tz":240,"elapsed":22212,"user":{"displayName":"Jessica Doanes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXCvogNc-f4f4YHOD66m7xFkY-udmCBRFz-8H8=s64","userId":"14664671934116168292"}},"outputId":"f7ca9cd3-c8e3-4342-cc4e-07759addc318"},"source":["import os\n","from pyspark.sql.functions import col,regexp_replace, when, expr, \n","# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n","# For example:\n","# spark_version = 'spark-3.0.2'\n","spark_version = 'spark-3.0.3'\n","os.environ['SPARK_VERSION']=spark_version\n","\n","# Install Spark and Java\n","!apt-get update\n","!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n","!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n","!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","\n","# Set Environment Variables\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n","\n","# Start a SparkSession\n","import findspark\n","findspark.init()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [1 InRelease 14.2 kB/88.7\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting f\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n","\r                                                                               \r0% [Waiting for headers] [Waiting for headers] [Waiting for headers]\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","\r                                                                               \r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Waiting for headers]\r                                                                         \rHit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n","\r                                                                         \rHit:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connecting to ppa.launchpa\r                                                                               \rIgn:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connecting to ppa.launchpa\r                                                                               \rHit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n","Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n","Hit:10 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n","Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Fetched 88.7 kB in 3s (33.6 kB/s)\n","Reading package lists... Done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C7f0JZq7mf_O","executionInfo":{"status":"ok","timestamp":1629249001612,"user_tz":240,"elapsed":577,"user":{"displayName":"Jessica Doanes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXCvogNc-f4f4YHOD66m7xFkY-udmCBRFz-8H8=s64","userId":"14664671934116168292"}},"outputId":"2be6d440-9f1a-4579-ac5e-486c0d4d915d"},"source":["from pyspark.sql import SparkSession\n","import pandas as pd\n","spark = SparkSession.builder.appName(\"CloudETL\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.9.jar\").getOrCreate()\n","from pyspark import SparkFiles\n","\n","#df=spark.read.csv(SparkFiles.get(\"combined_csv(1).csv\"),sep=\",\",header=True,inferSchema=True)\n","\n","url='https://project3group5.s3.amazonaws.com/SVDemo_combined.csv'\n","\n","spark.sparkContext.addFile(url)\n","#df = spark.read.csv(SparkFiles.get)\n","df=spark.read.csv(SparkFiles.get(\"SVDemo_combined.csv\"),sep=\",\")\n","df.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+-------+----+------------------+------+--------------------+-----+------------+------------+------------+\n","|    _c0| _c1|               _c2|   _c3|                 _c4|  _c5|         _c6|         _c7|         _c8|\n","+-------+----+------------------+------+--------------------+-----+------------+------------+------------+\n","|company|year|              race|gender|        job_category|count|valuation   |ownership   |eeo-1 status|\n","|23andMe|2016|Hispanic_or_Latino|  male|          Executives|    0|       $1.1b|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|  male|            Managers|    1|       $1.1b|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|  male|       Professionals|    7|       $1.1b|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|  male|         Technicians|    0|       $1.1b|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|  male|       Sales workers|    0|       $1.1b|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|  male|Administrative su...|    0|       $1.1b|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|  male|       Craft workers|    0|       $1.1b|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|  male|          operatives|    0|       $1.1b|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|  male|laborers and helpers|    0|       $1.1b|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|  male|     Service workers|    0|       $1.1b|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|  male|              Totals|    8|       $1.1b|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|  male|     Previous_totals|   na|       $1.1b|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|female|          Executives|    0|       $1.1b|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|female|            Managers|    1|       $1.1b|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|female|       Professionals|    5|       $1.1b|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|female|         Technicians|    0|       $1.1b|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|female|       Sales workers|    0|       $1.1b|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|female|Administrative su...|    5|       $1.1b|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|female|       Craft workers|    0|       $1.1b|     private|         YES|\n","+-------+----+------------------+------+--------------------+-----+------------+------------+------------+\n","only showing top 20 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vFd21AOyxxTQ","executionInfo":{"status":"ok","timestamp":1629248504869,"user_tz":240,"elapsed":111,"user":{"displayName":"Jessica Doanes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXCvogNc-f4f4YHOD66m7xFkY-udmCBRFz-8H8=s64","userId":"14664671934116168292"}},"outputId":"437b812f-3047-4da4-9f60-06fccccd5661"},"source":["df.columns"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['_c0', '_c1', '_c2', '_c3', '_c4', '_c5', '_c6', '_c7', '_c8']"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ub4KiEXHvvQX","executionInfo":{"status":"ok","timestamp":1629252542894,"user_tz":240,"elapsed":254,"user":{"displayName":"Jessica Doanes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXCvogNc-f4f4YHOD66m7xFkY-udmCBRFz-8H8=s64","userId":"14664671934116168292"}},"outputId":"3e14c78c-7851-4422-f1cc-bb04a2f72a60"},"source":["# Create a new column called `Salary` where the values are the `Salary (1k)` * 1000\n","# Show bthe columns `Salary` and `Salary (1k)`\n","#df = df.withColumn(\"_c6\", df[\"_c62)\"] * 1000)\n","#df.select([\"_c6\", \"_c62\"]).show()\n","\n","df_without = df.withColumn('_c6',\n","              when(df._c6.endswith('b'),regexp_replace(df._c6, 'b', '')))\n","df_nodollar = df_without.withColumn('_c6', regexp_replace('_c6','[$,]', '')).show()\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+-------+----+------------------+------+--------------------+-----+----+------------+------------+\n","|    _c0| _c1|               _c2|   _c3|                 _c4|  _c5| _c6|         _c7|         _c8|\n","+-------+----+------------------+------+--------------------+-----+----+------------+------------+\n","|company|year|              race|gender|        job_category|count|null|ownership   |eeo-1 status|\n","|23andMe|2016|Hispanic_or_Latino|  male|          Executives|    0| 1.1|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|  male|            Managers|    1| 1.1|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|  male|       Professionals|    7| 1.1|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|  male|         Technicians|    0| 1.1|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|  male|       Sales workers|    0| 1.1|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|  male|Administrative su...|    0| 1.1|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|  male|       Craft workers|    0| 1.1|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|  male|          operatives|    0| 1.1|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|  male|laborers and helpers|    0| 1.1|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|  male|     Service workers|    0| 1.1|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|  male|              Totals|    8| 1.1|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|  male|     Previous_totals|   na| 1.1|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|female|          Executives|    0| 1.1|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|female|            Managers|    1| 1.1|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|female|       Professionals|    5| 1.1|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|female|         Technicians|    0| 1.1|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|female|       Sales workers|    0| 1.1|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|female|Administrative su...|    5| 1.1|     private|         YES|\n","|23andMe|2016|Hispanic_or_Latino|female|       Craft workers|    0| 1.1|     private|         YES|\n","+-------+----+------------------+------+--------------------+-----+----+------------+------------+\n","only showing top 20 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":164},"id":"DHgphtJ1kWjL","executionInfo":{"status":"error","timestamp":1629412787230,"user_tz":240,"elapsed":236,"user":{"displayName":"Jessica Doanes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXCvogNc-f4f4YHOD66m7xFkY-udmCBRFz-8H8=s64","userId":"14664671934116168292"}},"outputId":"60e87d83-a337-4460-ea59-319df77ec096"},"source":["df.value = pd.to_numeric(df_nodollar._c6, errors='coerce') "],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-6fc26e54814d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_nodollar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'coerce'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317},"id":"L14v1hYtF-f2","executionInfo":{"status":"error","timestamp":1629254358346,"user_tz":240,"elapsed":124,"user":{"displayName":"Jessica Doanes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXCvogNc-f4f4YHOD66m7xFkY-udmCBRFz-8H8=s64","userId":"14664671934116168292"}},"outputId":"f252f60c-3bfd-4793-84c1-0e92bc4b9bd1"},"source":["# df1 = df.select('*',df.area.cast(\"string\"))\n","\n","new_df = df_nodollar.select('_c6',df_nodollar.area.cast(\"string\")).show()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-82-1647eda504d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# df1 = df.select('*',df.area.cast(\"string\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnew_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_nodollar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_c6'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_nodollar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marea\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"string\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5139\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5140\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5141\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'select'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":351},"id":"ilL7yk_SCPdw","executionInfo":{"status":"error","timestamp":1629253682741,"user_tz":240,"elapsed":115,"user":{"displayName":"Jessica Doanes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXCvogNc-f4f4YHOD66m7xFkY-udmCBRFz-8H8=s64","userId":"14664671934116168292"}},"outputId":"7fe558aa-62b9-444c-e024-1ad73437110a"},"source":["#df_newval = pd.DataFrame(df_nodollar)\n","#df_newval['_c6'] = df['_c6'].astype(int)\n","\n","#print (df_newval)\n","#print (df_newval.dtypes)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-74-ab336f09962d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_newval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_nodollar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_newval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_c6'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_c6'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_newval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_newval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/column.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(self, dataType)\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unexpected type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: unexpected type: <class 'type'>"]}]}]}